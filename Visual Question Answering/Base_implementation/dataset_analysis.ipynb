{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = r'E:\\VQA\\floodnet\\Images'\n",
    "training_questions_path = r'E:\\VQA\\floodnet\\Questions\\Training Question.json'\n",
    "validation_questions_path = r'E:\\VQA\\floodnet\\Questions\\Valid Question.json'\n",
    "test_questions_path = r'E:\\VQA\\floodnet\\Questions\\Test_Question.json'\n",
    "\n",
    "def load_questions_and_images(json_file_path, image_dir, split='Train_Image'):\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    questions = []\n",
    "    answers = []\n",
    "    image_paths = []\n",
    "    question_types = []\n",
    "\n",
    "    for item in data:\n",
    "        questions.append(data[item]['Question'])\n",
    "        answers.append(data[item]['Ground_Truth'])\n",
    "        question_types.append(data[item]['Question_Type'])\n",
    "        image_paths.append(os.path.join(image_dir, split, data[item]['Image_ID']))\n",
    "\n",
    "    return questions, answers, question_types, image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Questions: ['What is the overall condition of the given image?', 'What is the overall condition of the given image?', 'What is the overall condition of the given image?', 'How many non flooded buildings can be seen in this image?', 'How many buildings can be seen in the image?']\n",
      "Training Answers: ['flooded', 'flooded', 'non flooded', 3, 3]\n",
      "Training Question Types: ['Condition_Recognition', 'Condition_Recognition', 'Condition_Recognition', 'Complex_Counting', 'Simple_Counting']\n",
      "Training Image Paths: ['E:\\\\VQA\\\\floodnet\\\\Images\\\\Train_Image\\\\10165.JPG', 'E:\\\\VQA\\\\floodnet\\\\Images\\\\Train_Image\\\\10166.JPG', 'E:\\\\VQA\\\\floodnet\\\\Images\\\\Train_Image\\\\10168.JPG', 'E:\\\\VQA\\\\floodnet\\\\Images\\\\Train_Image\\\\10168.JPG', 'E:\\\\VQA\\\\floodnet\\\\Images\\\\Train_Image\\\\10168.JPG']\n"
     ]
    }
   ],
   "source": [
    "train_questions, train_answers, Question_Types, train_image_paths = load_questions_and_images(training_questions_path, image_dir)\n",
    "\n",
    "print(\"Training Questions:\", train_questions[:5])\n",
    "print(\"Training Answers:\", train_answers[:5])\n",
    "print(\"Training Question Types:\", Question_Types[:5])\n",
    "print(\"Training Image Paths:\", train_image_paths[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Question_Type</th>\n",
       "      <th>Image_Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the overall condition of the given image?</td>\n",
       "      <td>flooded</td>\n",
       "      <td>Condition_Recognition</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10165.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the overall condition of the given image?</td>\n",
       "      <td>flooded</td>\n",
       "      <td>Condition_Recognition</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10166.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the overall condition of the given image?</td>\n",
       "      <td>non flooded</td>\n",
       "      <td>Condition_Recognition</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10168.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many non flooded buildings can be seen in ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Complex_Counting</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10168.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many buildings can be seen in the image?</td>\n",
       "      <td>3</td>\n",
       "      <td>Simple_Counting</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10168.JPG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question       Answer  \\\n",
       "0  What is the overall condition of the given image?      flooded   \n",
       "1  What is the overall condition of the given image?      flooded   \n",
       "2  What is the overall condition of the given image?  non flooded   \n",
       "3  How many non flooded buildings can be seen in ...            3   \n",
       "4       How many buildings can be seen in the image?            3   \n",
       "\n",
       "           Question_Type                                    Image_Path  \n",
       "0  Condition_Recognition  E:\\VQA\\floodnet\\Images\\Train_Image\\10165.JPG  \n",
       "1  Condition_Recognition  E:\\VQA\\floodnet\\Images\\Train_Image\\10166.JPG  \n",
       "2  Condition_Recognition  E:\\VQA\\floodnet\\Images\\Train_Image\\10168.JPG  \n",
       "3       Complex_Counting  E:\\VQA\\floodnet\\Images\\Train_Image\\10168.JPG  \n",
       "4        Simple_Counting  E:\\VQA\\floodnet\\Images\\Train_Image\\10168.JPG  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame({\n",
    "    'Question': train_questions,\n",
    "    'Answer': train_answers,\n",
    "    'Question_Type': Question_Types,\n",
    "    'Image_Path': train_image_paths\n",
    "})\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Question_Type\n",
       "Condition_Recognition    2315\n",
       "Yes_No                    867\n",
       "Complex_Counting          693\n",
       "Simple_Counting           636\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Question_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Question\n",
       "What is the overall condition of the given image?            1448\n",
       "What is the condition of road?                                452\n",
       "Is the entire road non flooded?                               441\n",
       "Is the entire road flooded?                                   426\n",
       "What is the condition of the road in this image?              415\n",
       "How many buildings are non flooded?                           183\n",
       "How many non flooded buildings can be seen in this image?     179\n",
       "How many buildings are non flooded in this image?             179\n",
       "How many buildings can be seen in this image?                 173\n",
       "How many buildings are in this image?                         169\n",
       "How many buildings can be seen in the image?                  151\n",
       "How many buildings are in the image?                          143\n",
       "How many flooded buildings can be seen in this image?          55\n",
       "How many buildings are flooded?                                49\n",
       "How many buildings are flooded in this image?                  48\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Question'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Question_Type</th>\n",
       "      <th>Image_Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many buildings can be seen in the image?</td>\n",
       "      <td>3</td>\n",
       "      <td>Simple_Counting</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10168.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How many buildings can be seen in this image?</td>\n",
       "      <td>4</td>\n",
       "      <td>Simple_Counting</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10170.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>How many buildings are in this image?</td>\n",
       "      <td>4</td>\n",
       "      <td>Simple_Counting</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10171.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How many buildings can be seen in this image?</td>\n",
       "      <td>7</td>\n",
       "      <td>Simple_Counting</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10172.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>How many buildings can be seen in the image?</td>\n",
       "      <td>1</td>\n",
       "      <td>Simple_Counting</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10175.JPG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Question Answer    Question_Type  \\\n",
       "4    How many buildings can be seen in the image?      3  Simple_Counting   \n",
       "6   How many buildings can be seen in this image?      4  Simple_Counting   \n",
       "13          How many buildings are in this image?      4  Simple_Counting   \n",
       "19  How many buildings can be seen in this image?      7  Simple_Counting   \n",
       "23   How many buildings can be seen in the image?      1  Simple_Counting   \n",
       "\n",
       "                                      Image_Path  \n",
       "4   E:\\VQA\\floodnet\\Images\\Train_Image\\10168.JPG  \n",
       "6   E:\\VQA\\floodnet\\Images\\Train_Image\\10170.JPG  \n",
       "13  E:\\VQA\\floodnet\\Images\\Train_Image\\10171.JPG  \n",
       "19  E:\\VQA\\floodnet\\Images\\Train_Image\\10172.JPG  \n",
       "23  E:\\VQA\\floodnet\\Images\\Train_Image\\10175.JPG  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['Question_Type'] == 'Simple_Counting'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Question_Type</th>\n",
       "      <th>Image_Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many non flooded buildings can be seen in ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Complex_Counting</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10168.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How many buildings are non flooded?</td>\n",
       "      <td>4</td>\n",
       "      <td>Complex_Counting</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10170.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>How many buildings are non flooded?</td>\n",
       "      <td>4</td>\n",
       "      <td>Complex_Counting</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10171.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How many buildings are non flooded in this image?</td>\n",
       "      <td>7</td>\n",
       "      <td>Complex_Counting</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10172.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>How many buildings are non flooded in this image?</td>\n",
       "      <td>1</td>\n",
       "      <td>Complex_Counting</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10175.JPG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Question Answer  \\\n",
       "3   How many non flooded buildings can be seen in ...      3   \n",
       "9                 How many buildings are non flooded?      4   \n",
       "14                How many buildings are non flooded?      4   \n",
       "17  How many buildings are non flooded in this image?      7   \n",
       "21  How many buildings are non flooded in this image?      1   \n",
       "\n",
       "       Question_Type                                    Image_Path  \n",
       "3   Complex_Counting  E:\\VQA\\floodnet\\Images\\Train_Image\\10168.JPG  \n",
       "9   Complex_Counting  E:\\VQA\\floodnet\\Images\\Train_Image\\10170.JPG  \n",
       "14  Complex_Counting  E:\\VQA\\floodnet\\Images\\Train_Image\\10171.JPG  \n",
       "17  Complex_Counting  E:\\VQA\\floodnet\\Images\\Train_Image\\10172.JPG  \n",
       "21  Complex_Counting  E:\\VQA\\floodnet\\Images\\Train_Image\\10175.JPG  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['Question_Type'] == 'Complex_Counting'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Question_Type</th>\n",
       "      <th>Image_Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Is the entire road non flooded?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes_No</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10170.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Is the entire road flooded?</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes_No</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10171.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Is the entire road flooded?</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes_No</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10172.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Is the entire road non flooded?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes_No</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10175.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Is the entire road non flooded?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes_No</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10176.JPG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Question Answer Question_Type  \\\n",
       "7   Is the entire road non flooded?    Yes        Yes_No   \n",
       "10      Is the entire road flooded?     No        Yes_No   \n",
       "18      Is the entire road flooded?     No        Yes_No   \n",
       "24  Is the entire road non flooded?    Yes        Yes_No   \n",
       "27  Is the entire road non flooded?    Yes        Yes_No   \n",
       "\n",
       "                                      Image_Path  \n",
       "7   E:\\VQA\\floodnet\\Images\\Train_Image\\10170.JPG  \n",
       "10  E:\\VQA\\floodnet\\Images\\Train_Image\\10171.JPG  \n",
       "18  E:\\VQA\\floodnet\\Images\\Train_Image\\10172.JPG  \n",
       "24  E:\\VQA\\floodnet\\Images\\Train_Image\\10175.JPG  \n",
       "27  E:\\VQA\\floodnet\\Images\\Train_Image\\10176.JPG  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['Question_Type'] == 'Yes_No'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Question_Type</th>\n",
       "      <th>Image_Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the overall condition of the given image?</td>\n",
       "      <td>flooded</td>\n",
       "      <td>Condition_Recognition</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10165.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the overall condition of the given image?</td>\n",
       "      <td>flooded</td>\n",
       "      <td>Condition_Recognition</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10166.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the overall condition of the given image?</td>\n",
       "      <td>non flooded</td>\n",
       "      <td>Condition_Recognition</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10168.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the overall condition of the given image?</td>\n",
       "      <td>non flooded</td>\n",
       "      <td>Condition_Recognition</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10170.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the condition of the road in this image?</td>\n",
       "      <td>non flooded</td>\n",
       "      <td>Condition_Recognition</td>\n",
       "      <td>E:\\VQA\\floodnet\\Images\\Train_Image\\10170.JPG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question       Answer  \\\n",
       "0  What is the overall condition of the given image?      flooded   \n",
       "1  What is the overall condition of the given image?      flooded   \n",
       "2  What is the overall condition of the given image?  non flooded   \n",
       "5  What is the overall condition of the given image?  non flooded   \n",
       "8   What is the condition of the road in this image?  non flooded   \n",
       "\n",
       "           Question_Type                                    Image_Path  \n",
       "0  Condition_Recognition  E:\\VQA\\floodnet\\Images\\Train_Image\\10165.JPG  \n",
       "1  Condition_Recognition  E:\\VQA\\floodnet\\Images\\Train_Image\\10166.JPG  \n",
       "2  Condition_Recognition  E:\\VQA\\floodnet\\Images\\Train_Image\\10168.JPG  \n",
       "5  Condition_Recognition  E:\\VQA\\floodnet\\Images\\Train_Image\\10170.JPG  \n",
       "8  Condition_Recognition  E:\\VQA\\floodnet\\Images\\Train_Image\\10170.JPG  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['Question_Type'] == 'Condition_Recognition'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.models import vgg16\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class VQADataset(Dataset):\n",
    "    def __init__(self, questions, answers, image_paths, transform=None):\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        question = self.questions[idx]\n",
    "        answer = self.answers[idx]\n",
    "        \n",
    "        return image, question, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_questions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m      2\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)),\n\u001b[0;32m      3\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m      4\u001b[0m ])\n\u001b[1;32m----> 7\u001b[0m dataset \u001b[38;5;241m=\u001b[39m VQADataset(\u001b[43mtrain_questions\u001b[49m, train_answers, train_image_paths, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m      8\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_questions' is not defined"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "dataset = VQADataset(train_questions, train_answers, train_image_paths, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImageFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        vgg_model = vgg16(pretrained=False)  \n",
    "        self.feature_extractor = nn.Sequential(*list(vgg_model.features.children())[:-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        return x\n",
    "\n",
    "class QuestionFeatureExtractor(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        return hidden[-1] \n",
    "\n",
    "class VQAModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.img_feature_extractor = ImageFeatureExtractor()\n",
    "        self.question_feature_extractor = QuestionFeatureExtractor(embedding_dim=300, hidden_dim=1024)\n",
    "        self.fc = nn.Linear(25088 + 1024, 1024)  \n",
    "        self.classifier = nn.Linear(1024, 4) # Output layer for 4 question types\n",
    "\n",
    "    def forward(self, image, question):\n",
    "        img_features = self.img_feature_extractor(image)\n",
    "        question_features = self.question_feature_extractor(question)\n",
    "        combined_features = torch.cat((img_features, question_features), dim=1)\n",
    "        combined_features = F.relu(self.fc(combined_features))\n",
    "        output = self.classifier(combined_features)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdul Manaf\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Abdul Manaf\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = VQAModel().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VQAModel(\n",
       "  (img_feature_extractor): ImageFeatureExtractor(\n",
       "    (feature_extractor): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (question_feature_extractor): QuestionFeatureExtractor(\n",
       "    (lstm): LSTM(300, 1024, num_layers=2, batch_first=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=26112, out_features=1024, bias=True)\n",
       "  (classifier): Linear(in_features=1024, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, questions, answers in dataloader:\n",
    "        images, questions, answers = images.to(device), questions.to(device), answers.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, questions)\n",
    "        loss = criterion(outputs, answers)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
