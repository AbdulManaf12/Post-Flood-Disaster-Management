{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras.utils import normalize\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib.patches import Rectangle\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "seed = 42\n",
    "SIZE_X = 128\n",
    "SIZE_Y = 128\n",
    "n_channels = 3\n",
    "n_classes = 10\n",
    "Batch_size = 8\n",
    "EPOCHS = 100\n",
    "MODEL = 'unet'\n",
    "BACKBONE = 'vgg16'\n",
    "encoder_weights = 'imagenet'\n",
    "activation = 'softmax'\n",
    "parent_directory = r'E:\\Segmentation\\datasets\\FloodNet-Supervised_v1.0(customized)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(images, masks, unet_preporcessing):\n",
    "    if unet_preporcessing:\n",
    "        images = unet_preporcessing(images)\n",
    "    else:\n",
    "        images = normalize(images, axis=1)\n",
    "        \n",
    "    masks = np.expand_dims(masks, axis=-1)\n",
    "    masks = to_categorical(masks, num_classes=n_classes)\n",
    "    masks = masks.reshape((masks.shape[0], masks.shape[1], masks.shape[2], n_classes))\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "def preprocess_mask(mask, num_classes=10):\n",
    "    mask = np.squeeze(mask) \n",
    "    mask = to_categorical(mask, num_classes=num_classes)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map= {'Background':0, 'Building-flooded':1, 'Building-non-flooded':2, 'Road-flooded':3, 'Road-non-flooded':4, 'Water':5, 'Tree':6, 'Vehicle':7, 'Pool':8, 'Grass':9}\n",
    "    \n",
    "color_map = {'Background':[0, 0, 0], 'Building-flooded':[196, 0, 0], 'Building-non-flooded': [255,128,128], 'Road-flooded':[128, 128, 0],  'Road-non-flooded':[128, 128, 128], \n",
    "                 'Water': [0, 191, 255], 'Tree':[34, 139, 34], 'Vehicle': [123, 37, 118],  'Pool':[0, 68, 255],'Grass':[127, 224, 104]}\n",
    "\n",
    "handles = [Rectangle((0,0),1,1, color = (np.array(c)/255)) for n,c in color_map.items()]\n",
    "\n",
    "labels = [n for n,c in color_map.items()]\n",
    "\n",
    "\n",
    "def to_RGB(label):\n",
    "    \"\"\"\n",
    "    Suply our labale masks as input in RGB format. \n",
    "    Replace pixels with specific RGB values ...\n",
    "    \"\"\"    \n",
    "    label_seg = np.zeros(label.shape,dtype=np.uint8)\n",
    "    for key, val in class_map.items():\n",
    "      label_seg [np.all(label == class_map[key],axis=-1)] = color_map[key]  \n",
    "    return label_seg\n",
    "\n",
    "def display_images_with_masks(image, mask, predicted=None):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(131)\n",
    "    plt.title('Testing Image')\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(132)\n",
    "    plt.title('Testing Label')\n",
    "    plt.imshow(to_RGB(mask)) \n",
    "    plt.subplot(133)\n",
    "    plt.title('Prediction')\n",
    "    plt.imshow(to_RGB(predicted))\n",
    "    plt.legend(handles, labels, bbox_to_anchor =(-0.8,-0.5), loc='lower center', ncol=5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1445 images belonging to 1 classes.\n",
      "Found 1445 images belonging to 1 classes.\n",
      "Found 450 images belonging to 1 classes.\n",
      "Found 450 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "img_data_gen_args = dict(rescale = 1/255.)\n",
    "mask_data_gen_args = dict()\n",
    "\n",
    "image_data_generator = ImageDataGenerator(**img_data_gen_args)\n",
    "image_generator = image_data_generator.flow_from_directory(f\"{parent_directory}\\\\train_images\", \n",
    "                                                           seed=seed, \n",
    "                                                           batch_size=Batch_size,\n",
    "                                                           class_mode=None) \n",
    "\n",
    "mask_data_generator = ImageDataGenerator(**mask_data_gen_args)\n",
    "mask_generator = mask_data_generator.flow_from_directory(f\"{parent_directory}\\\\train_masks\", \n",
    "                                                         seed=seed, \n",
    "                                                         batch_size=Batch_size,\n",
    "                                                         color_mode = 'grayscale',\n",
    "                                                         class_mode=None,\n",
    "                                                         target_size=(SIZE_X, SIZE_Y))\n",
    "\n",
    "\n",
    "valid_img_generator = image_data_generator.flow_from_directory(f\"{parent_directory}\\\\val_images\", \n",
    "                                                           seed=seed, \n",
    "                                                           batch_size=Batch_size,\n",
    "                                                           class_mode=None) \n",
    "\n",
    "valid_mask_generator = mask_data_generator.flow_from_directory(f\"{parent_directory}\\\\val_masks\", \n",
    "                                                         seed=seed, \n",
    "                                                         batch_size=Batch_size,\n",
    "                                                         color_mode = 'grayscale',\n",
    "                                                         class_mode=None,\n",
    "                                                         target_size=(SIZE_X, SIZE_Y))\n",
    "\n",
    "\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "val_generator = zip(valid_img_generator, valid_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_batch, y_train_batch = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 256, 256, 3), (8, 128, 128, 1))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_batch.shape, y_train_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = to_categorical(y_train_batch.squeeze(), num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 10)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
