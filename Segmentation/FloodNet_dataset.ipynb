{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from enum import Enum\n",
    "from patchify import patchify\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Rescaling\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib.patches import Rectangle\n",
    "from keras.models import Model, load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"E:\\Segmentation\\datasets\\FloodNet-Supervised_v1.0\"\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training data: {len(os.listdir(os.path.join(data_dir, 'train', 'train-org-img')))}\")\n",
    "print(f\"Validation data: {len(os.listdir(os.path.join(data_dir, 'val', 'val-org-img')))}\")\n",
    "print(f\"Test data: {len(os.listdir(os.path.join(data_dir, 'test', 'test-org-img')))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_masks(data_dir, split=\"train\"):\n",
    "    image_list = []\n",
    "    mask_list = []\n",
    "\n",
    "    for file in tqdm(os.listdir(os.path.join(data_dir, f\"{split}/{split}-org-img\"))):\n",
    "        if file.endswith(\".jpg\"): \n",
    "            image_path = os.path.join(data_dir,  f\"{split}/{split}-org-img\", file)\n",
    "            mask_path = (os.path.join(data_dir,  f\"{split}/{split}-label-img\", file[:-4] + \"_lab.png\"))\n",
    "\n",
    "            image = cv2.imread(image_path)\n",
    "            mask = cv2.imread(mask_path)\n",
    "\n",
    "            image_list.append(np.asarray(image))\n",
    "            mask_list.append(np.asarray(mask))\n",
    "\n",
    "    return image_list, mask_list\n",
    "\n",
    "\n",
    "# X_train, Y_train = load_images_and_masks(f'{data_dir}/', \"train\")\n",
    "X_val, Y_val = load_images_and_masks(f'{data_dir}/', \"val\")\n",
    "# X_test, Y_test = load_images_and_masks(f'{data_dir}/', \"test\")\n",
    "\n",
    "# print(f\"Training data: {len(X_train)}\")\n",
    "print(f\"Validation data: {len(X_val)}\")\n",
    "# print(f\"Test data: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is the source of color map used:\n",
    "Source: https://github.com/farshadsafavi/BiseNetV2/blob/main/colors.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map= {'Background':0, 'Building-flooded':1, 'Building-non-flooded':2, 'Road-flooded':3, 'Road-non-flooded':4, 'Water':5, 'Tree':6, 'Vehicle':7, 'Pool':8, 'Grass':9}\n",
    "\n",
    "color_map = {\n",
    "    \"Background\": [0, 0, 0],\n",
    "    \"Building-flooded\": [255, 0, 0],\n",
    "    \"Building-non-flooded\": [0, 255, 0],\n",
    "    \"Road-flooded\": [0, 255, 120],\n",
    "    \"Road-non-flooded\": [0, 0, 255],\n",
    "    \"Water\": [255, 0, 255],\n",
    "    \"Tree\": [70, 70, 70],\n",
    "    \"Vehicle\": [102, 102, 156],\n",
    "    \"Pool\": [190, 153, 153],\n",
    "    \"Grass\": [180, 165, 180]\n",
    "}\n",
    "\n",
    "handles = [\n",
    "    Rectangle((0, 0), 1, 1, color=np.array(c)/255) for n, c in color_map.items()\n",
    "]\n",
    "labels = [n for n, c in color_map.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_with_masks(images, masks, class_map, color_map):\n",
    "    for i in range(5):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Image')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        mask_colored = np.zeros_like(images[i], dtype=np.uint8)\n",
    "        for class_name, class_idx in class_map.items():\n",
    "            color = color_map[class_name]\n",
    "            mask_indices = np.where(masks[i] == class_idx)\n",
    "            mask_colored[mask_indices[0], mask_indices[1], :] = color\n",
    "        plt.imshow(cv2.cvtColor(mask_colored, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Colored Mask')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(masks[i], cmap='viridis')\n",
    "        plt.title('Original Mask')\n",
    "\n",
    "        plt.legend(handles, labels, bbox_to_anchor =(-0.8,-0.5), loc='lower center', ncol=5)\n",
    "        plt.show()\n",
    "\n",
    "display_images_with_masks(X_val[10:], Y_val[10:], class_map, color_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envpython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
