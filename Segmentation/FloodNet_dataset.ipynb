{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from enum import Enum\n",
    "from patchify import patchify\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Rescaling\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib.patches import Rectangle\n",
    "from keras.models import Model, load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"E:\\Segmentation\\datasets\\FloodNet-Supervised_v1.0\"\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 1445\n",
      "Validation data: 450\n",
      "Test data: 448\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training data: {len(os.listdir(os.path.join(data_dir, 'train', 'train-org-img')))}\")\n",
    "print(f\"Validation data: {len(os.listdir(os.path.join(data_dir, 'val', 'val-org-img')))}\")\n",
    "print(f\"Test data: {len(os.listdir(os.path.join(data_dir, 'test', 'test-org-img')))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450/450 [03:48<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data: 450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def load_images_and_masks(data_dir, split=\"train\"):\n",
    "    image_list = []\n",
    "    mask_list = []\n",
    "\n",
    "    for file in tqdm(os.listdir(os.path.join(data_dir, f\"{split}/{split}-org-img\"))):\n",
    "        if file.endswith(\".jpg\"): \n",
    "            image_path = os.path.join(data_dir,  f\"{split}/{split}-org-img\", file)\n",
    "            mask_path = (os.path.join(data_dir,  f\"{split}/{split}-label-img\", file[:-4] + \".png\"))\n",
    "\n",
    "            image = cv2.imread(image_path)\n",
    "            mask = cv2.imread(mask_path)\n",
    "\n",
    "            image_list.append(image)\n",
    "            mask_list.append(mask)\n",
    "\n",
    "    return image_list, mask_list\n",
    "\n",
    "\n",
    "# X_train, Y_train = load_images_and_masks(f'{data_dir}/', \"train\")\n",
    "X_val, Y_val = load_images_and_masks(f'{data_dir}/', \"val\")\n",
    "# X_test, Y_test = load_images_and_masks(f'{data_dir}/', \"test\")\n",
    "\n",
    "# print(f\"Training data: {len(X_train)}\")\n",
    "print(f\"Validation data: {len(X_val)}\")\n",
    "# print(f\"Test data: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map= {'Background':0, 'Building-flooded':1, 'Building-non-flooded':2, 'Road-flooded':3, 'Road-non-flooded':4, 'Water':5, 'Tree':6, 'Vehicle':7, 'Pool':8, 'Grass':9}\n",
    "    \n",
    "color_map = {'Background':[0, 0, 0], 'Building-flooded':[196, 0, 0], 'Building-non-flooded': [255,128,128], 'Road-flooded':[128, 128, 0],  'Road-non-flooded':[128, 128, 128], \n",
    "                 'Water': [0, 191, 255], 'Tree':[34, 139, 34], 'Vehicle': [123, 37, 118],  'Pool':[0, 68, 255],'Grass':[127, 224, 104]}\n",
    "\n",
    "handles = [Rectangle((0,0),1,1, color = (np.array(c)/255)) for n,c in color_map.items()]\n",
    "\n",
    "labels = [n for n,c in color_map.items()]\n",
    "\n",
    "\n",
    "def to_RGB(label):\n",
    "    \"\"\"\n",
    "    Suply our labale masks as input in RGB format. \n",
    "    Replace pixels with specific RGB values ...\n",
    "    \"\"\"    \n",
    "    label_seg = np.zeros(label.shape,dtype=np.uint8)\n",
    "    for key, val in class_map.items():\n",
    "      label_seg [np.all(label == class_map[key],axis=-1)] = color_map[key]  \n",
    "    return label_seg\n",
    "\n",
    "def display_images_with_masks(image, mask):\n",
    "    print(\"Image shape:\", image.shape)\n",
    "    print(\"Mask shape:\", to_RGB(mask).shape)\n",
    "\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    \n",
    "    plt.subplot(131)\n",
    "    plt.title('Testing Image')\n",
    "    plt.imshow(image)\n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.title('Testing Label')\n",
    "    plt.imshow(to_RGB(mask))\n",
    "\n",
    "    plt.legend(handles, labels, bbox_to_anchor=(-0.8, -0.5), loc='lower center', ncol=5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "X_val_array = np.array(X_val[10:])\n",
    "Y_val_array = np.array(Y_val[10:])\n",
    "display_images_with_masks(X_val_array, Y_val_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envpython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
